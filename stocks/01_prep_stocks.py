#!/usr/local/bin/python 

#GENERATED BY /aiservices/notebooks/stocks/01_GetData.ipynb

import os, datetime, glob, sys, time, datetime, colabexts, shutil, argparse
import matplotlib as mpl
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
from colabexts.jcommon import *
from alpha_vantage.timeseries import TimeSeries
from alpha_vantage.fundamentaldata import FundamentalData
import csv, requests

mpl.use('Agg')

#-----------------------------------------------------------------------------------
def create_sparkline(path, df5):
    ser = df5.close.values[::-1]
    popen = df5.iloc[-1].open
    
    fig=plt.figure(figsize=(2,1))
    plt.plot(ser, c= 'g')
    dd = [d if d <= popen else None for d in ser]
    plt.plot(dd, c='r')

    plt.xticks = []
    plt.yticks = []
    plt.grid(False)
    plt.axis('off')
    plt.axhline(y= popen, color='r', linestyle='--', alpha=0.5)
    plt.tight_layout()

    fig.savefig(f'{path}/trend.png', transparent=True)
    
    
#-----------------------------------------------------------------------------------
def processfiles(symbol='aapl', base='/opt/data/data/stocks/data/'):
    path = base+symbol
    file1= f'{path}/daily.csv'
    file2= f'{path}/daily_intraYahoo.csv'
    file3= f'{path}/daily_aug.csv'

    if not os.path.exists(file2):
        print(f"{file2} does not exit")
        return None, None

    df2 = pd.read_csv(file2)
    if (len (df2) <= 0 ):
        return None, None;
    df2.sort_values(df2.columns[0], inplace=True, ascending=False)
    df2.reset_index(drop=True, inplace=True)
    df2.columns = ['timestamp'] + [f.lower() for f in df2.columns[1:]]
    df2['timestamp'] = pd.to_datetime(df2['timestamp'] ).dt.tz_convert('UTC')
    
    if os.path.exists(file1) and os.path.exists(file2):
        df1 = pd.read_csv(file1)
        df2.columns = df1.columns
        
        df1['timestamp'] = pd.to_datetime(df1['timestamp']).dt.tz_localize('UTC')
        
        df3= pd.concat([df2,df1])
        df4 = df3.sort_values('timestamp', ascending=False)
        df4.reset_index(inplace=True, drop=True)
        df4.to_csv (file3, index=False)
        
    return df2, df4

#-----------------------------------------------------------------------------------
def summarize(symbol = 'aapl', base = '/opt/data/data/stocks/data/'):
    df2, df4 = processfiles(symbol)
    if ( df2 is None):
        print(f"Could not summarize!! for {symbol}")
        return
    
    path   = f'{base}{symbol}'
    
    #0. Create a sparkline
    create_sparkline(path, df2)
    
    #1. Read fundamentals data if available
    fundms = path+"/fundamentals.json"
    fds="{}"
    if (os.path.exists(fundms)):
        with open(fundms, "r") as f: fds = f.read()
    fundamentals = json.loads(fds) or {}

    # Read and get high/low etc.
    popen, high, low, price, vol = df2.open.values[-1], max(df2.high), min(df2.low), df2.close.values[0], max(df2.volume)
    prcnt_change = (price-popen)/popen*100
    
    stats=f'''{{
    "symbol": "{symbol.upper()}", "name": "{fundamentals.get('Name','')}",
    "open": {popen}, "high": {high}, "low": {low}, "price": {price}, "vol": {vol}, "percent_change": {prcnt_change},
    "trend" : "/static/stocks/data/{symbol}/trend.png"
    }}
    '''
    stats=json.loads(stats) # Just to make sure it loads
    summary_file = path+"/summary.json"
    with open(summary_file, "w") as f:
        f.write(json.dumps(stats, indent=3))
        
    return df2, df4, stats

#-----------------------------------------------------------------------------------
def readfile(file, ret=None):
    if not os.path.exists(file):
        return ret
    
    with (open(file, "r")) as f: 
        conts = f.read()
    return conts
#-----------------------------------------------------------------------------------
def create_list(base = "/opt/data/data/stocks/data/"):
    syms = f'{base}stocks_list.csv'
    
    sums=[]
    for k in  readfile(syms,"").split():
        k = k.lower()
        sfile = f'{base}/{k}/summary.json'
        print(f'Getting data for {k} from {sfile}')
        r = readfile(sfile, "{}")
        sums.append(json.loads(r))

    df = pd.DataFrame(sums)    
    df.fillna("--", inplace=True)
    df.to_csv(f'{base}/stocks.csv', index=False)
#-----------------------------------------------------------------------------------
def main(path="/opt/data/data/stocks/data/"):
    for (dirpath, dirnames, filenames) in os.walk(path):
        for d in dirnames:
            if ( os.path.exists(f'{path}{d}/daily.csv')):
                print(f'Processing {d}')
                summarize(d, path)
    create_list()
#-----------------------------------------------------------------------------------
if __name__ == '__main__':
    if (not inJupyter()):
        t1      = datetime.datetime.now()
        main()
        t2 = datetime.datetime.now()
        print(f"All Done in {str(t2-t1)} ***")
    else:
        pass
        
#df2, df4 = processfiles('aapl')
#create_fig(path, df2)

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Stock Price Data\n",
    "\n",
    "Steps to get the script working for you or just use the data in dat folder\n",
    "\n",
    "This works only on Mac and LINUX and I am not sure how this might translate in MSDOS systems such as Windows\n",
    "\n",
    "* go online to: https://rapidapi.com/\n",
    "* Register and get an API key\n",
    "* either put this in theis script directly OR\n",
    "> * Create a file in your home names \"~/.keys/keys.json\" with the key \n",
    "        {\n",
    "            \"AV_API_KEY\": \"YOUR API KEY HERE\" ,\n",
    "            \"NEWSAPI_KEY\": \"DONT WORRY ABOUT THIS FOR NOW\",\n",
    "        }\n",
    "\n",
    "This create files under your data/stock_price and a combined file named \"stockdata.csv\"\n",
    "You may use that file directly for your assignments\n",
    "\n",
    "\n",
    "This will pull prices for all the symbols stored in symbols.txt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting getstocksdata.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile  getstocksdata.py\n",
    "#!/usr/local/bin/python \n",
    "\n",
    "#GENERATED BY COMP4449/capstone/stock_prediction1/01_GetData.ipynb\n",
    "\n",
    "import os, datetime, glob, sys, time, datetime, colabexts, shutil, argparse\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from colabexts.jcommon import *\n",
    "\n",
    "#-----------------------------------------------------------------------------------\n",
    "def getkey(key='password'):\n",
    "    API_KEY, lines, file =None, None, os.path.expanduser('~/.keys/keys.json')\n",
    "    if os.path.exists(file):\n",
    "        with open(file, 'r') as f:\n",
    "            r = f.read()\n",
    "        j = eval(r)\n",
    "        return j['AV_API_KEY'], j['NEWSAPI_KEY']\n",
    "    else:\n",
    "        raise Exception (\"Please supply API_KEY\")\n",
    "\n",
    "    return avk, newsk;\n",
    "        \n",
    "\n",
    "#-----------------------------------------------------------------------------------\n",
    "'''\n",
    "This will read required symbols and saves them to data directory\n",
    "'''\n",
    "def save_data(symbol, API_KEY=\"\", check=True, savein=\"data/\"):\n",
    "    from alpha_vantage.timeseries import TimeSeries\n",
    "    if (savein and not savein.endswith(\"/\")):\n",
    "        savein = savein + \"/\"\n",
    "    outf = f'{savein}daily_{symbol}.csv'\n",
    "    if (check and os.path.exists(outf)):\n",
    "        dt = datetime.datetime.fromtimestamp(os.path.getmtime(outf))\n",
    "        dn = datetime.datetime.now()\n",
    "        ts = (dn - dt)\n",
    "        hr = (ts.days * 24 * 60 * 60 + ts.seconds)//60//60\n",
    "        if (hr < 8): #if it was created less than 4 hours ago\n",
    "            print(f\"{outf:22} exists, ... crested less than 8 hours!! at {dt} \")\n",
    "            return;\n",
    "    ts = TimeSeries(key=API_KEY, output_format='pandas')\n",
    "    \n",
    "    retry = 0\n",
    "    data = None\n",
    "    while retry <= 5:\n",
    "        try:\n",
    "            print(f\"Getting data for {symbol}\")\n",
    "            data, meta_data = ts.get_daily(symbol, outputsize='full')\n",
    "            break;\n",
    "        except ValueError as ve:\n",
    "            retry += 1\n",
    "            print(f\"Sleep for a Minute, {retry}/5 attempts\");\n",
    "            time.sleep(60)\n",
    "            \n",
    "    if data is None:\n",
    "        print(f\"Could not get data for {symbol}\")\n",
    "        return data\n",
    "    \n",
    "    data.insert(0, 'timestamp', value=data.index)\n",
    "\n",
    "    data.columns = 'timestamp,open,high,low,close,volume'.split(',')\n",
    "    print( f\"saving to output: {outf}\" )\n",
    "    data.to_csv(outf, index=False)\n",
    "    return data\n",
    "\n",
    "'''\n",
    "Read all the files in data with daily_*, reads them and returns a list\n",
    "'''\n",
    "def read_data(dirname=\"\", pattern=\"daily_*\"):\n",
    "    a={}\n",
    "    for f in glob.glob( f'{dirname}/{pattern}'):\n",
    "        symbol = os.path.basename(os.path.splitext(f)[0]).split(\"_\")[1]\n",
    "        print(f'Reading {f} Symbol: {symbol}')\n",
    "        df = pd.read_csv(f)\n",
    "        df.sort_values(by='timestamp', ascending=False, inplace=True)\n",
    "        df.index=(range(0,len(df)))\n",
    "        ncs = ['timestamp'] + [f'{symbol}_{c}' for c in df.columns[1:]]\n",
    "        df.columns = ncs\n",
    "        a[symbol] = df\n",
    "        \n",
    "    minrows = min([len(d) for d in a.values()])\n",
    "    return a, minrows, df\n",
    "\n",
    "'''\n",
    "Combines all the dataframes into one\n",
    "\n",
    "The problem for us to join multiple index funds from ASIA is that they have different holidays\n",
    "Therefore we have gaps in the trading days. Therefore \n",
    "'''\n",
    "def combine_data(a):\n",
    "    # Different excahnges have various holidays, therefore values may be missing  \n",
    "    # Get All Data Frames and their corresponding time stamps\n",
    "    #\n",
    "    ar=np.array([d['timestamp'].values for d in a.values()])\n",
    "    at=np.concatenate(ar)\n",
    "    at=set(at)\n",
    "    af = pd.DataFrame()\n",
    "    af['timestamp'] = list(at);\n",
    "\n",
    "    for k,v in a.items():\n",
    "        #print(f\"Getting {k:32} \\r\", end='')\n",
    "        af=pd.merge(af,v, how=\"left\", left_on=\"timestamp\".split(), right_on=\"timestamp\".split())\n",
    "    print()\n",
    "    af.sort_values(by='timestamp', ascending=True, inplace=True)\n",
    "    af.dropna(inplace=True)\n",
    "    af = af.reset_index(drop=True)\n",
    "    #af = af.fillna(method='ffill' ).fillna(method='bfill')\n",
    "    return af\n",
    "\n",
    "#-----------------------------------------------------------------------------------\n",
    "def getCombined(dirname=\"\", output=\"stockdata.csv\"):\n",
    "    if (not output):\n",
    "        print ( \"No output specified, Nothing to do!!!\")\n",
    "        \n",
    "    #Get All data together\n",
    "    a, maxrows, ldf  = read_data(dirname)\n",
    "    af = combine_data(a)\n",
    "    \n",
    "    if (os.path.exists(output)):\n",
    "        print(f\"{output} exists; moving it to backup {output}.BAK\")\n",
    "        shutil.copyfile( output, output+\".BAK\")\n",
    "\n",
    "    dname = os.path.dirname(output)\n",
    "    if dname and not os.path.exists(dname):\n",
    "        print(\"Making directories: \", dname)\n",
    "        os.makedirs(os.path.dirname(stockfile))\n",
    "            \n",
    "    print ( f\"Saving top output {output}!!!\")\n",
    "    af.to_csv(output, index=False)\n",
    "    return af    \n",
    "\n",
    "#-----------------------------------------------------------------------------------\n",
    "def getdata(symbols='MSFT GLD GOOGL SPX AAPL IBM', savein=\"\" ):\n",
    "    API_KEY = None  # Put your API KEY if you need to test data download or just use the data\n",
    "    API_KEY, NEWS_API_KEY = API_KEY or getkey()\n",
    "\n",
    "    for f in symbols.split():\n",
    "        if ( not f or f.startswith ('#')):\n",
    "            print( f'ignoring {f}')\n",
    "            continue; # empty lines\n",
    "        kv = f.split(':')\n",
    "        k = kv[0]\n",
    "        v = kv[1] if len(kv) > 1 else k \n",
    "        print(f'getting data for {k} => symbol {v}')\n",
    "        save_data(k, API_KEY=API_KEY, savein=savein)\n",
    "\n",
    "#-----------------------------------------------------------------------------------\n",
    "sysargs = None\n",
    "ASIA    = '6758.T:TOKYO  6501.T:HITACHI 0168.HK:HNGKNG 601288.SS:SHANGAI  SHNZEN'\n",
    "ASIA    = '601288.SS:SHANGAI'\n",
    "defsyms = f\"MSFT GLD GOOGL AAPL IBM {ASIA}\"\n",
    "deffile = \"symbols.txt\"\n",
    "defoutp = \"data/stock_price/stockdata.csv\"\n",
    "def addargs():\n",
    "    global sysargs\n",
    "    p = argparse.ArgumentParser(f\"{os.path.basename(sys.argv[0])}:\")\n",
    "    p.add_argument('-s', '--symbols', type=str, default=defsyms, help=f\"Symbols separated ex: '{defsyms}'\")\n",
    "    p.add_argument('-f', '--file'   , type=str, default=deffile, help=f\"Symbols from file ex: '{deffile}'\")\n",
    "    p.add_argument('-o', '--output' , type=str, default=defoutp, help= f\"o/p def: {defoutp}\")\n",
    "#    p.add_argument('args', nargs=argparse.REMAINDER)\n",
    "#    p.add_argument('input_files',action=\"store\", type=str, nargs='+', help=\"input file(s)\")\n",
    "\n",
    "    try:\n",
    "        sysargs, unknown=p.parse_known_args(sys.argv[1:])\n",
    "    except argparse.ArgumentError as exc:\n",
    "        print(exc.message )\n",
    "        \n",
    "    if (unknown):\n",
    "        print(\"Unknown options: \", unknown)\n",
    "        #p.print_help()\n",
    "    return sysargs\n",
    "#-----------------------------------------------------------------------------------\n",
    "if __name__ == '__main__':\n",
    "    if (not inJupyter()):\n",
    "        t1      = datetime.datetime.now()\n",
    "        sysargs = addargs()\n",
    "        symbs   = sysargs.symbols\n",
    "        if ( os.path.exists(sysargs.file)):\n",
    "            symbs += \"\\n\" + colabexts.jcommon.readFile(sysargs.file)\n",
    "           \n",
    "        dname   = os.path.dirname(sysargs.output) +\"/\"\n",
    "        getdata(symbs, savein=dname)\n",
    "        #getCombined(dname, sysargs.output);\n",
    "        t2 = datetime.datetime.now()\n",
    "        print(f\"All Done in {str(t2-t1)} ***\")\n",
    "    else:\n",
    "        pass\n",
    "        '''\n",
    "        a, minrows, ldf  = read_data()\n",
    "        stockfile=\"data/stockdata.csv\"\n",
    "        af= combine_data(a, stockfile)\n",
    "        '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
